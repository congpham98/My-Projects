{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16_pretrained.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5JTazI464C7e","colab_type":"code","colab":{}},"source":[" !wget http://download1499.mediafire.com/vsbtrxxkbk5g/forhwmpnp888mrl/GlassOrNot_dataset.rar\n"," !pip install unrar\n"," !unrar x '/content/GlassOrNot_dataset.rar'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f6cPELwV2bNm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":151},"outputId":"9ca545c8-9c34-4d3f-853b-c34dcbfd0400","executionInfo":{"status":"ok","timestamp":1576547293381,"user_tz":-420,"elapsed":4687,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["import os\n","\n","print('start____________1')\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from tensorflow.keras.applications.vgg16 import VGG16\n","\n","ir = 244 #image_resize\n","pre_trained_model = VGG16(input_shape = (ir,ir,3), include_top = False, weights='imagenet')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["start____________1\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L5rZUl1iGSgb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"95d60cec-69ec-4ab1-e1db-7b63343c7cca","executionInfo":{"status":"ok","timestamp":1576547293383,"user_tz":-420,"elapsed":4663,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["last_layer = pre_trained_model.get_layer('block5_pool')\n","print('last layer output shape:', last_layer.output_shape)\n","last_output = last_layer.output"],"execution_count":3,"outputs":[{"output_type":"stream","text":["last layer output shape: (None, 7, 7, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bpe3h9TFGUPn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4e1ea4cc-892f-4a5b-9732-705c51215b3e","executionInfo":{"status":"ok","timestamp":1576547293386,"user_tz":-420,"elapsed":4633,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["for layer in pre_trained_model.layers:\n","    layer.trainable = False\n","print('done')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LINm6vMhGYOv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"174ba0d2-3a86-48d8-a785-1fc62d194a5f","executionInfo":{"status":"ok","timestamp":1576547293388,"user_tz":-420,"elapsed":4567,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(last_output)\n","# Add a fully connected layer with 1,024 hidden units and ReLU activation\n","x = layers.Dense(1024, activation='relu')(x)\n","# Add a dropout rate of 0.2\n","x = layers.Dropout(0.2)(x) #de tranh overfit\n","# Add a final sigmoid layer for classification\n","x = layers.Dense(1, activation='sigmoid')(x)\n","\n","#configure and compile the model\n","model = Model(pre_trained_model.input, x)\n","model.compile(loss='binary_crossentropy',\n","             optimizer='adam',\n","             metrics= ['accuracy'])\n","print('done')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IXWJEdMJGbTF","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9DKqlf12Gdhi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"d37989ec-9db5-43e2-b5ca-c94a9ca9092c","executionInfo":{"status":"ok","timestamp":1576567535758,"user_tz":-420,"elapsed":1760,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","#Data augmentation\n","train_datagen = ImageDataGenerator(\n","      rescale = 1./255,#dua du lieu ve khoang 0->1\n","      shear_range = 0.2,#cat ngau nhien mot goc theo chiu kim dong ho\n","      zoom_range = 0.2,\n","      horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","training_set = train_datagen.flow_from_directory(\n","    '/content/GlassOrNot/TrainingSet',\n","    target_size=(ir,ir),\n","    batch_size=2,\n","    class_mode='binary'#bieu dien thanh kieu binary\n",")\n","test_set = test_datagen.flow_from_directory(\n","    '/content/GlassOrNot/ValidationSet',\n","     target_size=(ir,ir),\n","    batch_size=2,\n","    class_mode='binary'\n",")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found 200 images belonging to 2 classes.\n","Found 20 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SKqvR1dhHHIg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"be4c0b58-f2d6-4b93-d049-c2ee5cbe3bab","executionInfo":{"status":"ok","timestamp":1576547314270,"user_tz":-420,"elapsed":25334,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["from IPython.display import display\n","from PIL import Image\n","from tensorflow.keras.optimizers import RMSprop\n","\n","# Configure and compile the model\n","model = Model(pre_trained_model.input, x)\n","model.compile(loss='binary_crossentropy',\n","              metrics=['acc'])\n","\n","model.fit_generator(\n","      training_set,\n","      epochs=2,\n","      validation_data=test_set,\n","      verbose=1)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n"," 99/100 [============================>.] - ETA: 0s - loss: 4.4843 - acc: 0.5657Epoch 1/2\n","100/100 [==============================] - 12s 116ms/step - loss: 4.6403 - acc: 0.5600 - val_loss: 0.9582 - val_acc: 0.7500\n","Epoch 2/2\n"," 99/100 [============================>.] - ETA: 0s - loss: 1.3574 - acc: 0.7980Epoch 1/2\n","100/100 [==============================] - 9s 89ms/step - loss: 1.3438 - acc: 0.8000 - val_loss: 2.2359 - val_acc: 0.7500\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f0f10280ba8>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"sufy6oLeI56r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"17b87bfb-4971-4416-eef0-163378856b34","executionInfo":{"status":"ok","timestamp":1576568735757,"user_tz":-420,"elapsed":5869,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["import os,random\n","from keras.preprocessing import image\n","from tensorflow.keras.models import load_model\n","import numpy as  np\n","ir=244 #image size\n","\n","model = load_model('/content/drive/My Drive/Colab Notebooks/VGG_pretrained_80')\n","\n","path = '../content/TestOfGlassOrNot/'\n","\n","imagelist = os.listdir(path)\n","print(len(imagelist))\n","total = 0\n","\n","y_true = []\n","y_pred = []\n","\n","img_list = []\n","\n","while(imagelist):\n","    a=random.choice(imagelist)\n","    print(a)\n","    imagelist.remove(a)\n","    test_image = image.load_img(path+a, target_size = (ir,ir))\n","\n","    img_list.append(test_image)\n","\n","    test_image = image.img_to_array(test_image)\n","    test_image = np.expand_dims(test_image,axis=0)\n","    result = model.predict(test_image)\n","    \n","    print(result[0][0])\n","    if( result[0][0] >=0.5):\n","        prediction = 'Yes'\n","        y_pred.append(1)\n","    else:\n","        prediction = 'No'\n","        y_pred.append(0)\n","    print('it is_______________________________:'+prediction)\n","    if(a.find(prediction,0,3)!=-1):\n","        total= total +1\n","        #print('TOTAL___:'+ str(total))\n","    if(a.find('Yes',0,3)==-1):\n","        y_true.append(0)\n","    else:\n","        y_true.append(1)\n","\n","print('TOTAL___:'+ str(total))\n","print(y_pred)\n","print(y_true)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["20\n","Noo127.jpg\n","0.9999999\n","it is_______________________________:Yes\n","Noo130.jpg\n","0.0012020888\n","it is_______________________________:No\n","Yes183.jpg\n","1.0\n","it is_______________________________:Yes\n","Noo124.jpg\n","0.0\n","it is_______________________________:No\n","Yes181.jpg\n","1.0\n","it is_______________________________:Yes\n","Yes185.jpg\n","1.0\n","it is_______________________________:Yes\n","Yes182.jpg\n","1.0\n","it is_______________________________:Yes\n","Noo125.jpg\n","1.0\n","it is_______________________________:Yes\n","Noo132.jpg\n","0.0\n","it is_______________________________:No\n","Yes179.jpg\n","1.0\n","it is_______________________________:Yes\n","Noo133.jpg\n","0.0\n","it is_______________________________:No\n","Noo128.jpg\n","0.0\n","it is_______________________________:No\n","Yes188.jpg\n","1.0\n","it is_______________________________:Yes\n","Noo131.jpg\n","0.0\n","it is_______________________________:No\n","Yes184.jpg\n","1.0\n","it is_______________________________:Yes\n","Yes180.jpg\n","1.0\n","it is_______________________________:Yes\n","Noo126.jpg\n","0.0\n","it is_______________________________:No\n","Noo129.jpg\n","0.0\n","it is_______________________________:No\n","Yes186.jpg\n","1.0\n","it is_______________________________:Yes\n","Yes187.jpg\n","1.0\n","it is_______________________________:Yes\n","TOTAL___:18\n","[1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1]\n","[0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1]\n","[<PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3C8EE80>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FE0782CB0F0>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3C8EF28>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BACFD0>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BB1DD8>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3C024E0>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAE630>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAE1D0>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAEB38>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAE470>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BF79B0>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAEDD8>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAEC88>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAED30>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAEE10>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAEBA8>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3C38908>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAE358>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAEB70>, <PIL.Image.Image image mode=RGB size=244x244 at 0x7FDEF3BAECF8>]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EQSB_KNRTrLh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1obqOu_Z_TnQIM7VUgzfeaZ7_fKqAN4Ci"},"outputId":"65f26f45-22ed-4fc8-eb77-af6efc8f3f63","executionInfo":{"status":"ok","timestamp":1576570857108,"user_tz":-420,"elapsed":23468,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["import matplotlib.pyplot as plt\n","\n","MyDict = {\n","    0:'No',\n","    1:'Yes'\n","}\n","\n","fig=plt.figure(figsize=(20, 90))\n","columns = 2\n","rows = 10\n","img_index = 0\n","for i in range(1, columns*rows +1):\n","    img = img_list[img_index]\n","    fig.add_subplot(rows, columns, i)\n","    plt.title('Prediction:  ' + MyDict[y_pred[img_index]], size=15, color = 'red')\n","    plt.imshow(np.real(img))\n","    img_index+= 1\n","plt.show()"],"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HUOP1-P701on","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"c153ae94-d60b-4c15-eeed-f52f4809ca7c","executionInfo":{"status":"ok","timestamp":1576570936322,"user_tz":-420,"elapsed":3004,"user":{"displayName":"CONG PHAM BA","photoUrl":"","userId":"11304407030401837180"}}},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","\n","print('accuracy = ',accuracy_score(y_true, y_pred))\n","cnf_matrix = confusion_matrix(y_true, y_pred)\n","print(cnf_matrix)\n","\n","def cm2pr_binary(cm):\n","    p = cm[0,0]/np.sum(cm[:,0])\n","    r = cm[0,0]/np.sum(cm[0])\n","    return (p, r)\n","\n","p,r=cm2pr_binary(cnf_matrix)\n","print('Precision: ' + str(p))\n","print('Recall: ' + str(r) )"],"execution_count":38,"outputs":[{"output_type":"stream","text":["accuracy =  0.9\n","[[ 8  2]\n"," [ 0 10]]\n","Precision: 1.0\n","Recall: 0.8\n"],"name":"stdout"}]}]}